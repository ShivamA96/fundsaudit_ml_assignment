{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2njxtM_aFEX",
        "outputId": "7e25d828-2509-4a32-ccb8-50521bde0fb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome to the Investment Return Analyzer\n",
            "Data loaded\n",
            "\n",
            "Choose prediction period:\n",
            "1: One month\n",
            "3: Three months\n",
            "6: Six months\n",
            "12: One year\n",
            "Enter number of months (1, 3, 6, 12): 6\n",
            "Enter number of recommendations (1-10): 5\n",
            "Predicting 6-month returns...\n",
            "Feature engineering and grid search for 6-month returns...\n",
            "Error during prediction: 'super' object has no attribute '__sklearn_tags__'\n",
            "Unexpected error: cannot unpack non-iterable NoneType object\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-2-a3df497e80e8>:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data[column].fillna(data[column].median(), inplace=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_tags.py:354: FutureWarning: The XGBRegressor or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "def clean_data(data):\n",
        "    data = data.copy()\n",
        "\n",
        "    numeric_columns = ['min_sip', 'min_lumpsum', 'expense_ratio', 'fund_size_cr',\n",
        "                       'fund_age_yr', 'sortino', 'alpha', 'sd', 'beta', 'sharpe',\n",
        "                       'risk_level', 'rating', 'returns_1yr', 'returns_3yr', 'returns_5yr']\n",
        "\n",
        "    for column in numeric_columns:\n",
        "        if column in data.columns:\n",
        "            data[column] = pd.to_numeric(data[column], errors='coerce')\n",
        "            data[column].fillna(data[column].median(), inplace=True)\n",
        "\n",
        "    data = pd.get_dummies(data, columns=['amc_name', 'category', 'sub_category'], drop_first=True)\n",
        "    return data\n",
        "\n",
        "def calculate_return(yearly_return, months):\n",
        "    return yearly_return * (months / 12)\n",
        "\n",
        "def feature_engineering_and_grid_search(data, months):\n",
        "    print(f\"Feature engineering and grid search for {months}-month returns...\")\n",
        "\n",
        "    basic_features = ['expense_ratio', 'fund_size_cr', 'fund_age_yr',\n",
        "                      'sortino', 'alpha', 'sd', 'beta', 'sharpe', 'risk_level']\n",
        "\n",
        "    X = data[basic_features]\n",
        "\n",
        "    if months <= 12:\n",
        "        y = data['returns_1yr'].apply(lambda x: calculate_return(x, months))\n",
        "    elif months <= 36:\n",
        "        y = data['returns_3yr'].apply(lambda x: calculate_return(x, months))\n",
        "    else:\n",
        "        y = data['returns_5yr'].apply(lambda x: calculate_return(x, months))\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    selector = SelectKBest(score_func=f_regression, k='all')\n",
        "    X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
        "    X_test_selected = selector.transform(X_test_scaled)\n",
        "\n",
        "    param_grid = {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [3, 5, 10],\n",
        "        'learning_rate': [0.01, 0.1, 0.2],\n",
        "        'subsample': [0.6, 0.8, 1.0],\n",
        "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "        'min_child_weight': [1, 5, 10]\n",
        "    }\n",
        "\n",
        "    grid_search = GridSearchCV(estimator=XGBRegressor(random_state=42),\n",
        "                               param_grid=param_grid, cv=3, scoring='r2', verbose=1)\n",
        "    grid_search.fit(X_train_selected, y_train)\n",
        "\n",
        "    best_model = grid_search.best_estimator_\n",
        "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "\n",
        "    y_pred_test = best_model.predict(X_test_selected)\n",
        "\n",
        "    r2 = r2_score(y_test, y_pred_test)\n",
        "    mse = mean_squared_error(y_test, y_pred_test)\n",
        "    rmse = np.sqrt(mse)\n",
        "\n",
        "    print(f\"R² Score: {r2:.2f}\")\n",
        "    print(f\"Mean Squared Error: {mse:.2f}\")\n",
        "    print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
        "\n",
        "    return best_model, selector, scaler, r2, mse, rmse\n",
        "\n",
        "def predict_returns(data, months, recommendations=5):\n",
        "    print(f\"Predicting {months}-month returns...\")\n",
        "    processed_data = clean_data(data)\n",
        "\n",
        "    try:\n",
        "        model, selector, scaler, r2, mse, rmse = feature_engineering_and_grid_search(processed_data, months)\n",
        "\n",
        "        all_data_scaled = scaler.transform(processed_data[['expense_ratio', 'fund_size_cr', 'fund_age_yr',\n",
        "                                                           'sortino', 'alpha', 'sd', 'beta', 'sharpe', 'risk_level']])\n",
        "        all_data_selected = selector.transform(all_data_scaled)\n",
        "        predictions = model.predict(all_data_selected)\n",
        "\n",
        "        results = pd.DataFrame({\n",
        "            'fund_name': data['scheme_name'],\n",
        "            f'predicted_{months}m_return': predictions,\n",
        "            'risk_level': data['risk_level'],\n",
        "            'expense_ratio': data['expense_ratio']\n",
        "        })\n",
        "\n",
        "        top_recommendations = results.sort_values(f'predicted_{months}m_return', ascending=False).head(recommendations)\n",
        "\n",
        "        print(\"Prediction completed.\")\n",
        "        return top_recommendations, r2, mse, rmse\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during prediction: {e}\")\n",
        "        return None\n",
        "\n",
        "def run_analyzer():\n",
        "    print(\"Welcome to the Investment Return Analyzer\")\n",
        "\n",
        "    try:\n",
        "        data = pd.read_csv('/content/sample_data/comprehensive_mutual_funds_data.csv')\n",
        "        print(\"Data loaded\")\n",
        "\n",
        "        while True:\n",
        "            print(\"\\nChoose prediction period:\")\n",
        "            print(\"1: One month\")\n",
        "            print(\"3: Three months\")\n",
        "            print(\"6: Six months\")\n",
        "            print(\"12: One year\")\n",
        "\n",
        "            months = int(input(\"Enter number of months (1, 3, 6, 12): \"))\n",
        "            recommendations = int(input(\"Enter number of recommendations (1-10): \"))\n",
        "\n",
        "            top_recommendations, r2, mse, rmse = predict_returns(data, months, recommendations)\n",
        "\n",
        "            if top_recommendations is not None:\n",
        "                print(top_recommendations)\n",
        "                print(f\"R² Score: {r2:.2f}\")\n",
        "                print(f\"Mean Squared Error: {mse:.2f}\")\n",
        "                print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
        "\n",
        "            continue_analysis = input(\"Analyze another period? (yes/no): \").strip().lower()\n",
        "            if continue_analysis != 'yes':\n",
        "                break\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(\"Data file not found\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "run_analyzer()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
